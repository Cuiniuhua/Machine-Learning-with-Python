{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
    "train_df.drop(['Id'], axis=1, inplace=True)\n",
    "test_df.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find columns which have null values, Usually it can be done by train_df.isnull().sum()\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].isnull().sum() != 0:\n",
    "        print(col, train_df[col].isnull().sum())\n",
    "        #print(train_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find columns which have null values, Usually it can be done by test_df.isnull().sum()\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].isnull().sum() != 0:\n",
    "        print(col, test_df[col].isnull().sum())\n",
    "        #print(test_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill NaN values. We don't need to do this, xgboost does it automatically\n",
    "#train_df.fillna(-1, inplace=True)\n",
    "#test_df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df[pd.isnull(train_df['PersonalField7'])].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scatter plot matrix\n",
    "#sns.pairplot(yelp, kind='reg')\n",
    "\n",
    "# limit scatter plot matrix and add regression lines\n",
    "#sns.pairplot(yelp, x_vars=['cool', 'useful', 'funny'], y_vars='stars', size=6, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many customers purchased insurance plan\n",
    "#sns.countplot(x=\"QuoteConversion_Flag\", data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "# how many customers bought or did not buy policy\n",
    "#sns.countplot(x='QuoteConversion_Flag', data=train_df, hue='Year', ax=ax1)\n",
    "\n",
    "# which year has highest number of policies bought\n",
    "#sns.countplot(x=train_df['Year'].loc[train_df['QuoteConversion_Flag'] == 1], order=[2013,2014,2015], ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# which month has highest number of policies bought\n",
    "#sns.countplot(x=train_df['Month'].loc[train_df['QuoteConversion_Flag'] == 1], order=[1,2,3,4,5,6,7,8,9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are some columns with non-numerical values(i.e. dtype='object'),\n",
    "# So, We will create a corresponding unique numerical value for each non-numerical value in a column of training and testing set.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for f in train_df.columns:\n",
    "    if train_df[f].dtype=='object':\n",
    "        #print(f)\n",
    "        lbl_encoder = LabelEncoder()\n",
    "        lbl_encoder.fit(np.unique(list(train_df[f].values) + list(test_df[f].values)))\n",
    "        train_df[f] = lbl_encoder.transform(list(train_df[f].values))\n",
    "        test_df[f] = lbl_encoder.transform(list(test_df[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(np.unique(list(train_df['Response'].values)))\n",
    "train_df['Response'] = lbl_encoder.transform(list(train_df['Response'].values))\n",
    "\n",
    "y_train = train_df['Response']\n",
    "X_train = train_df.drop('Response', axis=1)\n",
    "X_test  = test_df.copy()\n",
    "X_test = X_test[X_train.columns.tolist()] # maintain same column order between train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train.columns)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#train_df_non_null = train_df.dropna()\n",
    "traning_labels = train_df['Response']\n",
    "training_data = train_df.drop('Response', axis=1)\n",
    "print(training_data.shape)\n",
    "\n",
    "#testing_data = test_df.dropna()\n",
    "testing_data = test_df[training_data.columns.tolist()] # maintain same column order between train and test data\n",
    "print(testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "dtree = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth =5, min_samples_leaf = 20)\n",
    "selector = RFECV(dtree, step=1, cv=5)\n",
    "selector = selector.fit(training_data, traning_labels)\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, traning_labels, validation_labels = train_test_split(training_data, traning_labels, test_size=0.25)\n",
    "\n",
    "dtree = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth =5, min_samples_leaf = 20)\n",
    "dtree = dtree.fit(training_data, traning_labels)\n",
    "print(pd.DataFrame(dtree.feature_importances_, columns = [\"Imp\"], index = training_data.columns).sort_values(by=['Imp'], ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ceate_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "ceate_feature_map(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Feature Importance of the attributes\n",
    "xgb_params = {\"n_estimators\":25, \"objective\": \"multi:softmax\", \"num_class\":8, \"eta\": 0.025, \"max_depth\": 10, \"silent\": 1, \"eval_metric\": \"auc\"}\n",
    "num_rounds = 10\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, missing=np.nan)\n",
    "gbdt = xgb.train(xgb_params, dtrain, num_rounds)\n",
    "\n",
    "importance = gbdt.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(15, 30))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "#plt.gcf().savefig('feature_importance_xgb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Low Importance Features\n",
    "low_importance_features = []\n",
    "low_importance_features.append(df[0:24]['feature'].tolist())\n",
    "low_importance_features.append(df[0:41]['feature'].tolist())\n",
    "low_importance_features.append(df[0:61]['feature'].tolist())\n",
    "#low_importance_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(y_train, n_folds=5)\n",
    "for low_importance_feature_set in low_importance_features:\n",
    "    # Drop unwanted Features\n",
    "    X_train_reduced = X_train.drop(low_importance_feature_set, axis=1)\n",
    "    X_test_reduced = X_test.drop(low_importance_feature_set, axis=1)\n",
    "    \n",
    "    # 5 Fold Cross Validation with reduced features\n",
    "    xgb_clf = xgb.XGBClassifier(n_estimators=25,\n",
    "                            objective=\"multi:softmax\",\n",
    "                            max_depth=10,\n",
    "                            learning_rate=0.025,\n",
    "                            silent=True,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=0.8,\n",
    "                            missing=np.nan)\n",
    "\n",
    "\n",
    "    scores = []    \n",
    "    for train_index, test_index in skf:\n",
    "        xgb_clf.fit(X_train.iloc[train_index], y_train.iloc[train_index], eval_metric=\"auc\")\n",
    "        y_pred = xgb_clf.predict(X_train.iloc[test_index])\n",
    "        scores.append(metrics.accuracy_score(y_train.iloc[test_index], y_pred))\n",
    "\n",
    "    train_acc = np.array(scores).mean() * 100\n",
    "    print('XGBoostClassifier Cross Validation Accuracy With %s Reduced Features: %.2f%%' % (len(low_importance_feature_set), train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GridSearchCV with XGBoost \n",
    "xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                            nthread=-1,\n",
    "                            learning_rate=0.025,\n",
    "                            silent=True,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=0.8,\n",
    "                            missing=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "X_train_reduced = X_train.drop(low_importance_feature_set[0], axis=1)\n",
    "param_grid = {'max_depth': [6,8,],\n",
    "              'n_estimators': [200,500]}\n",
    "\n",
    "gs = GridSearchCV(xgb_clf,\n",
    "                  param_grid,\n",
    "                  scoring='roc_auc',\n",
    "                  cv=5,\n",
    "                  n_jobs=1,\n",
    "                  verbose=1)\n",
    "\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "gs.best_score_, gs.best_params_\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf = gs.best_estimator_\n",
    "#clf.fit(X_train, y_train)\n",
    "#y_pred_proba = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create submission\n",
    "#sample = pd.read_csv('data/sample_submission.csv')\n",
    "#sample.QuoteConversion_Flag = y_pred_proba\n",
    "#sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sample.to_csv('xgb_benchmark.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

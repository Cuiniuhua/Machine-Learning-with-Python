{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
    "test_df.drop(['QuoteNumber'], axis=1, inplace=True)\n",
    "train_df.drop(['QuoteNumber'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Date to Year, Month, and Week\n",
    "train_df['Date'] = pd.to_datetime(pd.Series(train_df['Original_Quote_Date']))\n",
    "train_df['Year']  = train_df['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "train_df['Month'] = train_df['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "train_df['Weekday']  = train_df['Date'].dt.dayofweek\n",
    "\n",
    "test_df['Date'] = pd.to_datetime(pd.Series(test_df['Original_Quote_Date']))\n",
    "test_df['Year']  = test_df['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "test_df['Month'] = test_df['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "test_df['Weekday']  = test_df['Date'].dt.dayofweek\n",
    "\n",
    "train_df.drop(['Original_Quote_Date', 'Date'], axis=1, inplace=True)\n",
    "test_df.drop(['Original_Quote_Date', 'Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df['Weekday'].head(20)\n",
    "features = train_df.columns.tolist()\n",
    "#features\n",
    "start, end = 1, len(features)\n",
    "while start < end:\n",
    "    sub_features = ['QuoteConversion_Flag'] + features[start:min(start + 14, end)]\n",
    "    plt.figure()\n",
    "    sns.heatmap(train_df[sub_features].corr())\n",
    "    start = start + 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are some columns with non-numerical values(i.e. dtype='object'),\n",
    "# So, We will create a corresponding unique numerical value for each non-numerical value in a column of training and testing set.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "for f in train_df.columns:\n",
    "    if train_df[f].dtype=='object':\n",
    "        print(f)\n",
    "        lbl_encoder = preprocessing.LabelEncoder()\n",
    "        lbl_encoder.fit(np.unique(list(train_df[f].values) + list(test_df[f].values)))\n",
    "        train_df[f] = lbl_encoder.transform(list(train_df[f].values))\n",
    "        test_df[f] = lbl_encoder.transform(list(test_df[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "y_train = train_df['QuoteConversion_Flag']\n",
    "X_train = train_df.drop('QuoteConversion_Flag', axis=1)\n",
    "X_test  = test_df.copy()\n",
    "X_test = X_test[X_train.columns.tolist()] # maintain same column order between train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train.columns)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ceate_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "ceate_feature_map(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Feature Importance of the attributes\n",
    "xgb_params = {\"n_estimators\":25, \"objective\": \"binary:logistic\", \"eta\": 0.025, \"max_depth\": 10, \"silent\": 1, \"eval_metric\": \"auc\"}\n",
    "num_rounds = 10\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, missing=np.nan)\n",
    "gbdt = xgb.train(xgb_params, dtrain, num_rounds)\n",
    "\n",
    "importance = gbdt.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(15, 30))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "#plt.gcf().savefig('feature_importance_xgb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Low Importance Features\n",
    "low_importance_features = []\n",
    "low_importance_features.append(df[0:21]['feature'].tolist())\n",
    "low_importance_features.append(df[0:41]['feature'].tolist())\n",
    "#low_importance_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for low_importance_feature_set in low_importance_features:\n",
    "    # Drop unwanted Features\n",
    "    X_train_reduced = X_train.drop(low_importance_feature_set, axis=1)\n",
    "    X_test_reduced = X_test.drop(low_importance_feature_set, axis=1)\n",
    "    \n",
    "    # 5 Fold Cross Validation with reduced features\n",
    "    xgb_clf = xgb.XGBClassifier(n_estimators=25,\n",
    "                            objective=\"binary:logistic\",\n",
    "                            nthread=-1,\n",
    "                            max_depth=10,\n",
    "                            learning_rate=0.025,\n",
    "                            silent=True,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=0.8,\n",
    "                            missing=np.nan)\n",
    "\n",
    "    scores = cross_val_score(xgb_clf,\n",
    "                             X_train_reduced, # training data\n",
    "                             y_train, # training labels\n",
    "                             cv=skf,\n",
    "                             scoring='roc_auc',  # which scoring metric?\n",
    "                             n_jobs=-1  # -1 = use all cores = faster\n",
    "                             )\n",
    "    print('XGBoostClassifier Cross Validation Accuracy With %s Reduced Features: %.2f%%' % (len(low_importance_feature_set), np.array(scores).mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GridSearchCV with XGBoost \n",
    "xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                            nthread=-1,\n",
    "                            silent=True,\n",
    "                            missing=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "X_train_reduced = X_train.drop(low_importance_feature_set[0], axis=1)\n",
    "X_test_reduced = X_test.drop(low_importance_feature_set[0], axis=1)\n",
    "param_grid = {'max_depth': [2,4,6,8,10],\n",
    "              'n_estimators': [50,100,200,500,1000],\n",
    "              'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "              'subsample': [0.9, 1.0],\n",
    "              'colsample_bytree': [0.8, 1.0]}\n",
    "\n",
    "t0 = time()\n",
    "gs = GridSearchCV(xgb_clf,\n",
    "                  param_grid,\n",
    "                  scoring='roc_auc',\n",
    "                  cv=5,\n",
    "                  n_jobs=32,\n",
    "                  verbose=1)\n",
    "\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train_reduced, y_train)\n",
    "y_pred_proba = clf.predict_proba(X_test_reduced)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create submission\n",
    "sample = pd.read_csv('data/sample_submission.csv')\n",
    "sample.QuoteConversion_Flag = y_pred_proba\n",
    "#sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample.to_csv('reduced_xgb_benchmark.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
